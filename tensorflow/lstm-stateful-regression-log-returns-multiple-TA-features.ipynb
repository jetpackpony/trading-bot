{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vvtaranov/Envs/tading-bot-tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "\n",
      "/Users/vvtaranov/Envs/tading-bot-tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning:\n",
      "\n",
      "Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from metrics import *\n",
    "from utils import *\n",
    "from data_utils import *\n",
    "from plotting import *\n",
    "from features import *\n",
    "import lstm\n",
    "import pdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "import plotly\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from plotly.graph_objs import *\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "#DATAFILE = '../analyser/rawData/2018-01-15_ETHBTC_1m_6_mon_slice_last_50k.csv'\n",
    "#DATAFILE = '../analyser/rawData/2018-01-15_ETHBTC_1m_6_mon_.csv'\n",
    "DATAFILE = '../analyser/rawData/2018-01-15_ETHBTC_1h_4_mon_.csv'\n",
    "#DATAFILE = '../analyser/rawData/2018-02-13_ETHBTC_5m_2_mon_.csv'\n",
    "#DATAFILE = '../analyser/rawData/test-sample-mixed.csv'\n",
    "#DATAFILE = '../analyser/rawData/test-sample-flat.csv'\n",
    "#DATAFILE = '../analyser/rawData/test-sample-falling.csv'\n",
    "#DATAFILE = '../analyser/rawData/2018-02-13_ETHBTC_1m_2_mon_.csv'\n",
    "#DATAFILE = '../analyser/rawData/test-sample-short.csv'\n",
    "#DATAFILE = 'test.csv'\n",
    "COLUMN_NAME = 'close'\n",
    "\n",
    "#DATAFILE = 'shampoo-data.csv'\n",
    "#COLUMN_NAME = 'Sales'\n",
    "#DATAFILE = 'sinwave.csv'\n",
    "#COLUMN_NAME = 'sin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(DATAFILE)\n",
    "prices = data[COLUMN_NAME]\n",
    "a = \"\"\"\n",
    "pricesLine = Scatter(\n",
    "            x=prices.index,\n",
    "            y=prices,\n",
    "            name='prices'\n",
    "            )\n",
    "iplot([pricesLine], config={ \"scrollZoom\": True })\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate features\n",
    "features = getFeatures(opn=data.open.values,\n",
    "                            close=data.close.values,\n",
    "                            high=data.high.values,\n",
    "                            low=data.low.values,\n",
    "                            volume=data.volume.values)\n",
    "# Remove the last value since it doesn't have a next one, so it doesn't have a known output\n",
    "features = features[:-1]\n",
    "nanFeatures = np.isnan(features).any(axis=1)\n",
    "# Remove the values with nans\n",
    "xdata = features[~nanFeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate outputs: log returns\n",
    "# Drop the nan at the start to align inputs with outputs\n",
    "diffPrices = np.log(prices).diff().dropna().values\n",
    "ydata = diffPrices[~nanFeatures]\n",
    "ydata = ydata.reshape(ydata.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples: (2316, 110)\n",
      "Test examples: (257, 110)\n"
     ]
    }
   ],
   "source": [
    "# Split training set and test set\n",
    "xtrain, xtest = splitDataset(0.9, 0.1, xdata)\n",
    "ytrain, ytest = splitDataset(0.9, 0.1, ydata)\n",
    "\n",
    "print('Training examples: {}'.format(xtrain.shape))\n",
    "print('Test examples: {}'.format(xtest.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize things set\n",
    "scaler = StandardScaler()\n",
    "xtrain = scaler.fit_transform(xtrain)\n",
    "xtest = scaler.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape to proper input form\n",
    "xtrain = xtrain.reshape(xtrain.shape[0], 1, xtrain.shape[1])\n",
    "xtest = xtest.reshape(xtest.shape[0], 1, xtest.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 10s 4ms/step - loss: 1.0383e-04\n",
      "1/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 10s 4ms/step - loss: 1.1595e-04\n",
      "2/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 1.0784e-04\n",
      "3/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 10s 4ms/step - loss: 9.7735e-05\n",
      "4/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0078e-04\n",
      "5/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 1.2672e-04\n",
      "6/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0960e-04\n",
      "7/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.1021e-04\n",
      "8/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0461e-04\n",
      "9/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 11s 5ms/step - loss: 1.1651e-04\n",
      "10/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 1.1222e-04\n",
      "11/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0585e-04\n",
      "12/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.8317e-05\n",
      "13/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0872e-04\n",
      "14/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0035e-04\n",
      "15/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0217e-04\n",
      "16/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0257e-04\n",
      "17/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0176e-04\n",
      "18/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.1269e-04\n",
      "19/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0673e-04\n",
      "20/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0367e-04\n",
      "21/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.1287e-04\n",
      "22/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0353e-04\n",
      "23/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0316e-04\n",
      "24/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0075e-04\n",
      "25/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.6704e-05\n",
      "26/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.9164e-05\n",
      "27/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 1.1043e-04\n",
      "28/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0414e-04\n",
      "29/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 1.0909e-04\n",
      "30/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 1.0511e-04\n",
      "31/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.5753e-05\n",
      "32/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0423e-04\n",
      "33/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.4849e-05\n",
      "34/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.6219e-05\n",
      "35/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0020e-04\n",
      "36/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.5791e-05\n",
      "37/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.8604e-05\n",
      "38/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0250e-04\n",
      "39/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.1702e-04\n",
      "40/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0524e-04\n",
      "41/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0326e-04\n",
      "42/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.4175e-05\n",
      "43/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.8136e-05\n",
      "44/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.9763e-05\n",
      "45/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0883e-04\n",
      "46/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.8915e-05\n",
      "47/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.1021e-04A: 0s\n",
      "48/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.9467e-05\n",
      "49/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.1106e-04\n",
      "50/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.1214e-04\n",
      "51/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0826e-04A: 0s - \n",
      "52/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.3894e-05\n",
      "53/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.1126e-04\n",
      "54/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.8268e-05\n",
      "55/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0189e-04\n",
      "56/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0309e-04\n",
      "57/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0830e-04\n",
      "58/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0471e-04\n",
      "59/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.6331e-05\n",
      "60/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0231e-04\n",
      "61/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.1085e-04\n",
      "62/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.4889e-05\n",
      "63/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 1.0873e-04\n",
      "64/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0204e-04\n",
      "65/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.4140e-05\n",
      "66/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.8824e-05\n",
      "67/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.7764e-05\n",
      "68/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.4733e-05\n",
      "69/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.9599e-05\n",
      "70/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.5581e-05\n",
      "71/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.8601e-05\n",
      "72/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0381e-04\n",
      "73/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.5066e-05\n",
      "74/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.1194e-04\n",
      "75/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.7666e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.9509e-05\n",
      "77/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.2192e-05\n",
      "78/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.4701e-05\n",
      "79/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.8450e-05\n",
      "80/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.7961e-05\n",
      "81/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.3090e-05\n",
      "82/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0371e-04\n",
      "83/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0194e-04\n",
      "84/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.6904e-05\n",
      "85/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.1344e-05\n",
      "86/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 8.3315e-05\n",
      "87/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.7705e-05\n",
      "88/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.4608e-05\n",
      "89/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0875e-04\n",
      "90/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0496e-04\n",
      "91/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.3306e-05\n",
      "92/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0098e-04\n",
      "93/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0236e-04\n",
      "94/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.1666e-05\n",
      "95/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.5570e-05\n",
      "96/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 8.6029e-05\n",
      "97/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0508e-04\n",
      "98/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.3676e-05\n",
      "99/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.5915e-05\n",
      "100/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.5814e-05\n",
      "101/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 8.9641e-05\n",
      "102/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0287e-04\n",
      "103/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 8.4946e-05\n",
      "104/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 8.9546e-05\n",
      "105/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0027e-04\n",
      "106/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.2898e-05\n",
      "107/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.7801e-05\n",
      "108/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.5359e-05\n",
      "109/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.3497e-05\n",
      "110/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 8.9303e-05\n",
      "111/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0145e-04\n",
      "112/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.3720e-05\n",
      "113/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0345e-04\n",
      "114/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0024e-04\n",
      "115/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0357e-04\n",
      "116/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.1703e-05\n",
      "117/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.8759e-05\n",
      "118/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.2982e-05\n",
      "119/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 10s 4ms/step - loss: 9.9690e-05\n",
      "120/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 10s 4ms/step - loss: 8.8507e-05\n",
      "121/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 1.0035e-04\n",
      "122/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.2074e-05\n",
      "123/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 8.8612e-05\n",
      "124/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.9881e-05\n",
      "125/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 1.0964e-04\n",
      "126/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.9895e-05\n",
      "127/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 1.0433e-04\n",
      "128/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 10s 4ms/step - loss: 9.4829e-05\n",
      "129/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.5588e-05\n",
      "130/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.8367e-05\n",
      "131/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.9063e-05\n",
      "132/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 8.9028e-05\n",
      "133/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 1.0799e-04\n",
      "134/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.6392e-05\n",
      "135/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.6224e-05\n",
      "136/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 10s 4ms/step - loss: 9.8342e-05\n",
      "137/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.8497e-05\n",
      "138/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 8.3415e-05\n",
      "139/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.6400e-05\n",
      "140/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.6723e-05\n",
      "141/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 10s 4ms/step - loss: 1.0066e-04\n",
      "142/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.5061e-05\n",
      "143/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 1.1173e-04\n",
      "144/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 10s 4ms/step - loss: 9.8240e-05\n",
      "145/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 10s 4ms/step - loss: 9.7125e-05\n",
      "146/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 1.0364e-04\n",
      "147/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 1.0343e-04\n",
      "148/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 1.0386e-04\n",
      "149/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 10s 4ms/step - loss: 9.3538e-05\n",
      "150/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.8746e-05\n",
      "151/200 epoch complete\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.1508e-05\n",
      "152/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 10s 4ms/step - loss: 1.0293e-04\n",
      "153/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.4792e-05\n",
      "154/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.3307e-05\n",
      "155/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 10s 4ms/step - loss: 9.6278e-05\n",
      "156/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.5933e-05\n",
      "157/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 8.6423e-05\n",
      "158/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 10s 4ms/step - loss: 9.5491e-05\n",
      "159/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.0033e-05\n",
      "160/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.7406e-05\n",
      "161/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 1.0222e-04\n",
      "162/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 10s 4ms/step - loss: 9.0377e-05\n",
      "163/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 10s 4ms/step - loss: 9.8783e-05\n",
      "164/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.1239e-05\n",
      "165/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 1.0198e-04\n",
      "166/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.6733e-05\n",
      "167/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.8895e-05\n",
      "168/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 10s 4ms/step - loss: 9.5614e-05\n",
      "169/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.2596e-05\n",
      "170/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 9.6002e-05\n",
      "171/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 8s 4ms/step - loss: 8.4155e-05\n",
      "172/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.2474e-05\n",
      "173/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 10s 4ms/step - loss: 8.8479e-05\n",
      "174/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 8.8237e-05\n",
      "175/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 10s 4ms/step - loss: 9.3237e-05\n",
      "176/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 1.0119e-04\n",
      "177/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.5184e-05\n",
      "178/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.6079e-05\n",
      "179/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.6843e-05\n",
      "180/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.4621e-05\n",
      "181/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 1.0407e-04TA: 0s - loss: 1.00\n",
      "182/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 10s 4ms/step - loss: 9.9878e-05\n",
      "183/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 8.7625e-05\n",
      "184/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.2823e-05\n",
      "185/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.0239e-05\n",
      "186/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.5993e-05\n",
      "187/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.6151e-05\n",
      "188/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 8.9455e-05\n",
      "189/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.1467e-05\n",
      "190/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 10s 4ms/step - loss: 9.9936e-05\n",
      "191/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.2919e-05\n",
      "192/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 8.7884e-05\n",
      "193/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 1.0108e-04\n",
      "194/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.5843e-05\n",
      "195/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.3270e-05\n",
      "196/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.3056e-05\n",
      "197/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.5684e-05\n",
      "198/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.9493e-05\n",
      "199/200 epoch complete\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 9s 4ms/step - loss: 9.5827e-05\n",
      "200/200 epoch complete\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "EPOCHS = 200\n",
    "\"\"\"\n",
    "model = Sequential()\n",
    "model.add(LSTM(128,\n",
    "    batch_input_shape=(1, xtrain.shape[1], xtrain.shape[2]),\n",
    "    stateful=True\n",
    "    ))\n",
    "model.add(Dense(64))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='loss',\n",
    "            factor=0.9,\n",
    "            patience=10,\n",
    "            min_lr=0.000001,\n",
    "            verbose=1)\n",
    "print(\"Start training for {} epochs\".format(EPOCHS))\n",
    "\"\"\"\n",
    "for i in range(EPOCHS):\n",
    "    model.fit(\n",
    "        xtrain,\n",
    "        ytrain,\n",
    "        epochs=1,\n",
    "        batch_size=1,\n",
    "        verbose=1,\n",
    "        shuffle=False,\n",
    "        callbacks=[reduce_lr]\n",
    "    )\n",
    "    model.reset_states()\n",
    "    print(\"{}/{} epoch complete\".format(i + 1, EPOCHS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "# Preseed with train data\n",
    "PRESEED_AMOUNT = 500\n",
    "preseedX = xtrain[-PRESEED_AMOUNT:]\n",
    "preseedX\n",
    "for i in range(preseedX.shape[0]):\n",
    "    model.predict(preseedX[i].reshape(1, preseedX.shape[1], preseedX.shape[2]))\n",
    "\n",
    "# Predict the values from test\n",
    "pred = np.array([[0]])\n",
    "for i in range(xtest.shape[0]):\n",
    "    pr = model.predict(xtest[i].reshape(1, xtest.shape[1], xtest.shape[2]))\n",
    "    pred = np.concatenate((pred, pr))\n",
    "\n",
    "pred = pred[1:]\n",
    "model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "name": "predictions",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256
         ],
         "y": [
          0.045086778700351715,
          0.0583319216966629,
          -0.007984213531017303,
          -0.08746018260717392,
          -0.11182944476604462,
          0.013724563643336296,
          0.0460851825773716,
          0.1292824000120163,
          -0.016640646383166313,
          -0.022218773141503334,
          -0.05492708459496498,
          -0.0686476081609726,
          -0.04582185670733452,
          0.002434684894979,
          -0.07079704105854034,
          -0.023117927834391594,
          0.033930856734514236,
          0.020772624760866165,
          0.008738646283745766,
          0.009380806237459183,
          -0.00012146774679422379,
          0.10657311975955963,
          0.018091246485710144,
          0.05051198974251747,
          -0.015306195244193077,
          0.06934100389480591,
          0.11616328358650208,
          0.09180769324302673,
          0.07902227342128754,
          0.07042594999074936,
          0.021266702562570572,
          -0.016931351274251938,
          -0.0009234822355210781,
          0.024283835664391518,
          0.0002593561075627804,
          -0.0021306215785443783,
          -0.02749180607497692,
          0.020989352837204933,
          0.020122436806559563,
          0.06571320444345474,
          -0.019914593547582626,
          0.009798762388527393,
          0.008820061571896076,
          0.008505311794579029,
          0.017606783658266068,
          0.010712004266679287,
          0.0012511704117059708,
          0.16838955879211426,
          0.11694062501192093,
          0.08431046456098557,
          0.07280629873275757,
          0.05673797056078911,
          0.011181285604834557,
          -0.012214487418532372,
          -0.07363977283239365,
          -0.05027727410197258,
          -0.01785343699157238,
          0.008009696379303932,
          0.00919675175100565,
          0.00919675175100565,
          0.00900033488869667,
          0.00919675175100565,
          0.00919675175100565,
          0.009107417427003384,
          0.005815061274915934,
          0.00919675175100565,
          0.009153824299573898,
          0.007934702560305595,
          0.00919675175100565,
          0.00919675175100565,
          0.00919675175100565,
          0.0020048734731972218,
          -0.018240973353385925,
          -0.03168525919318199,
          -0.0460522323846817,
          -0.07322421669960022,
          -0.01029282622039318,
          0.0052447859197855,
          -9.295390918850899e-05,
          -0.011267520487308502,
          0.00919675175100565,
          -0.018961818888783455,
          -0.018961818888783455,
          -0.018961818888783455,
          -0.018961818888783455,
          -0.0891423299908638,
          0.00919675175100565,
          -0.021515026688575745,
          -0.024272290989756584,
          -0.04984211549162865,
          0.04641090705990791,
          0.013191483914852142,
          0.02919689007103443,
          0.02733277902007103,
          0.019159790128469467,
          -0.05648744851350784,
          -0.09721854329109192,
          -0.014761419966816902,
          -0.05037733167409897,
          -0.09561466425657272,
          -0.12195771932601929,
          -0.022218773141503334,
          0.03005482442677021,
          0.01570991985499859,
          -0.04656394198536873,
          -0.04089634120464325,
          -0.028769752010703087,
          -0.05037733167409897,
          -0.05037733167409897,
          -0.05037733167409897,
          -0.049661338329315186,
          -0.05037733167409897,
          -0.021199146285653114,
          -0.06872569024562836,
          -0.022218773141503334,
          -0.0799148753285408,
          -0.0047289044596254826,
          -0.032484132796525955,
          -0.02150607481598854,
          -0.022058267146348953,
          -0.005553503055125475,
          0.03211086243391037,
          -0.016555670648813248,
          -0.023746389895677567,
          -0.03141875937581062,
          -0.05037733167409897,
          -0.0504850409924984,
          -0.05037733167409897,
          -0.060873180627822876,
          -0.03493816405534744,
          -0.05037733167409897,
          -0.027647117152810097,
          0.0493026077747345,
          -0.022218773141503334,
          -0.04485614597797394,
          -0.09050162136554718,
          -0.033144041895866394,
          -0.017350314185023308,
          -0.08890937268733978,
          -0.01792149245738983,
          0.004621198400855064,
          0.014483870938420296,
          -0.08385836333036423,
          -0.0425848588347435,
          0.0028700740076601505,
          -0.022048674523830414,
          0.009314199909567833,
          0.005585612263530493,
          0.00919675175100565,
          -0.008288029581308365,
          -0.023101763799786568,
          0.009690255858004093,
          -0.009992608800530434,
          0.0073599801398813725,
          0.041213832795619965,
          -0.06890175491571426,
          -0.0616241917014122,
          -0.020165516063570976,
          -0.0485403910279274,
          -0.03632477670907974,
          0.05061958730220795,
          -0.002550204750150442,
          0.008815579116344452,
          0.008216341026127338,
          0.021433956921100616,
          -0.055460475385189056,
          -0.12879011034965515,
          -0.05928512662649155,
          -0.024296944960951805,
          -0.02251381240785122,
          -0.03410797566175461,
          -0.04629099369049072,
          -0.03294806927442551,
          -0.020668944343924522,
          -0.024016423150897026,
          -0.05671832710504532,
          0.00023849261924624443,
          0.014760259538888931,
          -0.07631704956293106,
          -0.06682775914669037,
          -0.05018901824951172,
          -0.047944746911525726,
          0.005481370724737644,
          0.05451349914073944,
          0.014230391010642052,
          -0.002416305709630251,
          0.0052975742146372795,
          0.002470380626618862,
          -0.022335559129714966,
          0.0023713866248726845,
          -0.029490338638424873,
          -0.002020613756030798,
          -0.04181506484746933,
          -0.0905674546957016,
          -0.11461661756038666,
          -0.09981344640254974,
          0.00919675175100565,
          0.00919675175100565,
          -0.05889182537794113,
          -0.05613374710083008,
          -0.0573781356215477,
          0.00919675175100565,
          -0.002518783789128065,
          -0.00712713273242116,
          0.00919675175100565,
          0.008126111701130867,
          0.008504753932356834,
          0.008863432332873344,
          -0.020627638325095177,
          -0.012867739424109459,
          -0.022407090291380882,
          -0.018727179616689682,
          -0.04502754285931587,
          -0.03494659811258316,
          0.06019013002514839,
          0.03206430375576019,
          0.03175055980682373,
          -0.03082754649221897,
          -0.02264486253261566,
          -0.07939687371253967,
          -0.0514070950448513,
          0.0017383904196321964,
          -0.03174985200166702,
          -0.04041034355759621,
          -0.0491541363298893,
          -0.007376226130872965,
          -0.012452445924282074,
          0.015352251008152962,
          -7.248762995004654e-05,
          -0.04856143891811371,
          -0.031122298911213875,
          0.010568695142865181,
          0.018730787560343742,
          0.0507691465318203,
          0.027392003685235977,
          0.019535765051841736,
          -0.05796778202056885,
          -0.05796778202056885,
          -0.036209482699632645,
          0.014706199988722801,
          0.05495947599411011,
          0.015464892610907555,
          -0.07718844711780548,
          -0.01683049276471138,
          -0.017957357689738274,
          -0.0575641468167305,
          0.009051918983459473,
          0.016327911987900734,
          0.022888602688908577,
          0.060077644884586334,
          -0.02204807475209236,
          0.008384522050619125,
          0.01354517973959446,
          0.012128133326768875,
          0.00919675175100565,
          0.008786987513303757,
          0.00919675175100565
         ]
        },
        {
         "name": "actual",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256
         ],
         "y": [
          -0.003552236290177646,
          -0.012666909008795635,
          -0.02076749412872969,
          0.02508600208473588,
          0.020780129620841414,
          0.004654803302791777,
          0.020727462293734344,
          0.01816358159240261,
          -0.010888220024617201,
          0.024678120361828704,
          0.0010718580379895926,
          -0.059421056913079084,
          -0.039021012703291724,
          -0.024073395399226705,
          0.014394114070797936,
          0.010046625989691638,
          -0.028507186052972422,
          0.0012971554710761168,
          0.0008693014152818535,
          -0.049314935004217464,
          -0.024496713763953792,
          0.026509842793672966,
          0.005519572448409615,
          -0.006706312063975428,
          -0.026541743220834135,
          -0.03431845910632925,
          0.034283114050215335,
          0.0018362883894273985,
          -0.0025080819265821397,
          0.05103948649400092,
          -0.020509012139859006,
          0.021348896621132596,
          -0.010855083756600603,
          0.013437504616918172,
          0.007059147341333727,
          0.010339814022492622,
          0.002761206823129747,
          -0.02029415582679661,
          0.0180101306790732,
          0.008844107566840176,
          -0.008646719666077995,
          -0.006385475402310714,
          0.0051676288650086555,
          -0.02653206641560013,
          0.005363028285598315,
          -0.004551669214718945,
          0.02116534197070319,
          -0.01164738624918149,
          -0.001121968082998137,
          -0.01572202773059672,
          0.0011057337669400091,
          0.0134259673215813,
          0.003282535186605706,
          0.01989835389060879,
          0.03681594791059961,
          0.004869794108321557,
          0.03552113023246983,
          -0.006423548633785803,
          -0.00821876224209861,
          -0.006658091902823404,
          0.012797883097884988,
          -0.004570560103813737,
          -0.0007843077348783645,
          0.00776973726436081,
          -0.003011843245432022,
          0.0035307370974995145,
          0.01842819778156901,
          0.03155207922597869,
          0.0033326119375605145,
          -0.019692116984326713,
          0.009923745562807618,
          -0.004656006302834026,
          -0.008903623192677568,
          -0.015368619884505996,
          0.04134030963497182,
          0.07869562194433621,
          -0.020900204930283106,
          -0.0005175842552005427,
          0.050929463035037426,
          0.021404822615597396,
          -0.04125509845612285,
          0.02951417869882267,
          -0.02491543952770403,
          -0.011596594160742768,
          -0.009179095640128754,
          0.0026273825755209756,
          -0.007579153394410287,
          0.006695193195417115,
          -0.013870184717053924,
          -0.016451862454175625,
          0.02164196279692998,
          0.005835399463695712,
          -0.006105757419273772,
          0.015561175753995293,
          0.010329028745721835,
          -0.0003294089773970832,
          0.022349555785669217,
          -0.005868000138693041,
          -0.014717190097367272,
          0.01813360773825501,
          -0.013016157913833926,
          0.021186190557160423,
          0.013604959418924256,
          0.0003286023057005316,
          0.0042746154578607864,
          0.009878694826445322,
          0.0030601986885776533,
          0.014574677543021775,
          0.00852012979424499,
          -0.003550371532919705,
          0.007414677587578744,
          -0.005941932234082792,
          -0.016469099433571888,
          0.020183913169818712,
          -0.006394147941726214,
          -0.00757741673474932,
          -0.0050754651609259405,
          0.008154976590823093,
          0.0046686224391701,
          0.028641891547904308,
          0.027048894071283414,
          0.02517883095304807,
          0.008153619080335073,
          0.005539564105277339,
          0.000920284577006214,
          0.018654369142237837,
          0.0514129434895092,
          0.039099495130596296,
          -0.04868235889347661,
          0.004361568957226947,
          -0.023924284289515096,
          0.03962979477076756,
          -0.05719811148822895,
          0.004709398319483249,
          0.03391232759581042,
          -0.005190530861983511,
          0.00888162704403106,
          0.001089126990942102,
          -0.02807017411997892,
          -0.022121552330685912,
          -0.003483353871875927,
          -0.03245078230440157,
          0.0272523761779202,
          -0.01615039011257169,
          -0.026060770512618348,
          -0.026357682586857223,
          -0.012251192910883724,
          0.08687129278985495,
          -0.01849851719913609,
          0.01659500497357369,
          -0.017419214503096025,
          -0.0005907300145593375,
          -0.012035162344166572,
          0.012603606994637584,
          0.013161798839348204,
          -0.009724585713193346,
          0.008690322918270876,
          -0.01798347911028797,
          -0.003930601949734935,
          -0.01584445343334595,
          -0.0022202902364107935,
          -0.014413811447370417,
          0.017765239511832842,
          0.006612629018152294,
          0.01344253167288123,
          -0.0025102552572535686,
          -0.016780113231626537,
          0.004815007509873848,
          -0.005328609411218821,
          -0.008368825282802916,
          -0.0103452789767422,
          -0.0015831997905433326,
          0.017942775068036543,
          0.0021033386812434607,
          0.00905991726331079,
          -0.0036163944661851133,
          0.012886514523055226,
          -0.00924748794189778,
          0.004561217305778964,
          -0.005240403666658899,
          -0.0013824364807910605,
          -0.010166140687778213,
          0.0060073273396024085,
          0.03571188990388929,
          0.001482156754120112,
          0.00018648632396267573,
          -0.004804873481925043,
          0.0011345800242237303,
          0.00018713707845563476,
          0.0013089798977179434,
          0.002755351897718139,
          -0.005749827570366239,
          0.0035988879001749297,
          0.00027461211211976533,
          0.0029610154879780026,
          -0.0074080111927159464,
          -0.0008387780820218182,
          0.009833353056404537,
          -0.0026274031207504933,
          0.002233732464906879,
          0.013892053952895278,
          -0.0022461242219335986,
          0.008568589961420514,
          0.009419992313639547,
          -0.0068187651664857185,
          0.006861236577923258,
          0.0009975592464730454,
          0.006755032478160672,
          -0.008953103945650742,
          0.00037199415866684404,
          0.011074942267074839,
          0.006390266670196265,
          0.02043450276221037,
          0.017444661444583787,
          -0.010511517848760477,
          0.017225306281879682,
          -0.01309849494766313,
          -0.016085864273492678,
          0.00376667608072756,
          -0.018684594916501318,
          0.010403889878631833,
          -0.0012609690459575162,
          0.0021179334827565732,
          0.0033382476368024605,
          0.003142589777704874,
          0.006011120237823686,
          0.0016904969604936149,
          0.006339310113588237,
          0.00041445749624102746,
          0.004567852534890893,
          -0.013103852276032946,
          -0.010255869656194516,
          0.00793931752599164,
          -0.004228509277415693,
          -0.00174575671525945,
          0.0022176145101808764,
          -6.153404372932769e-05,
          -0.0010055924094016788,
          0.014047837925851958,
          -0.002838491829178391,
          0.0012681795209621427,
          0.0027439026171340863,
          0.009659966443797074,
          0.009339388217148414,
          -0.024494709617237653,
          0.006101844411858348,
          -0.003157769516003217,
          -0.007294809512189637,
          0.003923631891638024,
          -0.010408346951558567,
          0.002453359200121241,
          -0.002042335539923723,
          -0.009164718304578656,
          -0.0014006694376167417,
          -0.017966593856288515,
          -0.010274590607841194,
          -0.007719314005821598
         ]
        }
       ],
       "layout": {}
      },
      "text/html": [
       "<div id=\"ee03aa61-46d4-43be-9472-c5056ceee0c9\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"ee03aa61-46d4-43be-9472-c5056ceee0c9\", [{\"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256], \"y\": [0.045086778700351715, 0.0583319216966629, -0.007984213531017303, -0.08746018260717392, -0.11182944476604462, 0.013724563643336296, 0.0460851825773716, 0.1292824000120163, -0.016640646383166313, -0.022218773141503334, -0.05492708459496498, -0.0686476081609726, -0.04582185670733452, 0.002434684894979, -0.07079704105854034, -0.023117927834391594, 0.033930856734514236, 0.020772624760866165, 0.008738646283745766, 0.009380806237459183, -0.00012146774679422379, 0.10657311975955963, 0.018091246485710144, 0.05051198974251747, -0.015306195244193077, 0.06934100389480591, 0.11616328358650208, 0.09180769324302673, 0.07902227342128754, 0.07042594999074936, 0.021266702562570572, -0.016931351274251938, -0.0009234822355210781, 0.024283835664391518, 0.0002593561075627804, -0.0021306215785443783, -0.02749180607497692, 0.020989352837204933, 0.020122436806559563, 0.06571320444345474, -0.019914593547582626, 0.009798762388527393, 0.008820061571896076, 0.008505311794579029, 0.017606783658266068, 0.010712004266679287, 0.0012511704117059708, 0.16838955879211426, 0.11694062501192093, 0.08431046456098557, 0.07280629873275757, 0.05673797056078911, 0.011181285604834557, -0.012214487418532372, -0.07363977283239365, -0.05027727410197258, -0.01785343699157238, 0.008009696379303932, 0.00919675175100565, 0.00919675175100565, 0.00900033488869667, 0.00919675175100565, 0.00919675175100565, 0.009107417427003384, 0.005815061274915934, 0.00919675175100565, 0.009153824299573898, 0.007934702560305595, 0.00919675175100565, 0.00919675175100565, 0.00919675175100565, 0.0020048734731972218, -0.018240973353385925, -0.03168525919318199, -0.0460522323846817, -0.07322421669960022, -0.01029282622039318, 0.0052447859197855, -9.295390918850899e-05, -0.011267520487308502, 0.00919675175100565, -0.018961818888783455, -0.018961818888783455, -0.018961818888783455, -0.018961818888783455, -0.0891423299908638, 0.00919675175100565, -0.021515026688575745, -0.024272290989756584, -0.04984211549162865, 0.04641090705990791, 0.013191483914852142, 0.02919689007103443, 0.02733277902007103, 0.019159790128469467, -0.05648744851350784, -0.09721854329109192, -0.014761419966816902, -0.05037733167409897, -0.09561466425657272, -0.12195771932601929, -0.022218773141503334, 0.03005482442677021, 0.01570991985499859, -0.04656394198536873, -0.04089634120464325, -0.028769752010703087, -0.05037733167409897, -0.05037733167409897, -0.05037733167409897, -0.049661338329315186, -0.05037733167409897, -0.021199146285653114, -0.06872569024562836, -0.022218773141503334, -0.0799148753285408, -0.0047289044596254826, -0.032484132796525955, -0.02150607481598854, -0.022058267146348953, -0.005553503055125475, 0.03211086243391037, -0.016555670648813248, -0.023746389895677567, -0.03141875937581062, -0.05037733167409897, -0.0504850409924984, -0.05037733167409897, -0.060873180627822876, -0.03493816405534744, -0.05037733167409897, -0.027647117152810097, 0.0493026077747345, -0.022218773141503334, -0.04485614597797394, -0.09050162136554718, -0.033144041895866394, -0.017350314185023308, -0.08890937268733978, -0.01792149245738983, 0.004621198400855064, 0.014483870938420296, -0.08385836333036423, -0.0425848588347435, 0.0028700740076601505, -0.022048674523830414, 0.009314199909567833, 0.005585612263530493, 0.00919675175100565, -0.008288029581308365, -0.023101763799786568, 0.009690255858004093, -0.009992608800530434, 0.0073599801398813725, 0.041213832795619965, -0.06890175491571426, -0.0616241917014122, -0.020165516063570976, -0.0485403910279274, -0.03632477670907974, 0.05061958730220795, -0.002550204750150442, 0.008815579116344452, 0.008216341026127338, 0.021433956921100616, -0.055460475385189056, -0.12879011034965515, -0.05928512662649155, -0.024296944960951805, -0.02251381240785122, -0.03410797566175461, -0.04629099369049072, -0.03294806927442551, -0.020668944343924522, -0.024016423150897026, -0.05671832710504532, 0.00023849261924624443, 0.014760259538888931, -0.07631704956293106, -0.06682775914669037, -0.05018901824951172, -0.047944746911525726, 0.005481370724737644, 0.05451349914073944, 0.014230391010642052, -0.002416305709630251, 0.0052975742146372795, 0.002470380626618862, -0.022335559129714966, 0.0023713866248726845, -0.029490338638424873, -0.002020613756030798, -0.04181506484746933, -0.0905674546957016, -0.11461661756038666, -0.09981344640254974, 0.00919675175100565, 0.00919675175100565, -0.05889182537794113, -0.05613374710083008, -0.0573781356215477, 0.00919675175100565, -0.002518783789128065, -0.00712713273242116, 0.00919675175100565, 0.008126111701130867, 0.008504753932356834, 0.008863432332873344, -0.020627638325095177, -0.012867739424109459, -0.022407090291380882, -0.018727179616689682, -0.04502754285931587, -0.03494659811258316, 0.06019013002514839, 0.03206430375576019, 0.03175055980682373, -0.03082754649221897, -0.02264486253261566, -0.07939687371253967, -0.0514070950448513, 0.0017383904196321964, -0.03174985200166702, -0.04041034355759621, -0.0491541363298893, -0.007376226130872965, -0.012452445924282074, 0.015352251008152962, -7.248762995004654e-05, -0.04856143891811371, -0.031122298911213875, 0.010568695142865181, 0.018730787560343742, 0.0507691465318203, 0.027392003685235977, 0.019535765051841736, -0.05796778202056885, -0.05796778202056885, -0.036209482699632645, 0.014706199988722801, 0.05495947599411011, 0.015464892610907555, -0.07718844711780548, -0.01683049276471138, -0.017957357689738274, -0.0575641468167305, 0.009051918983459473, 0.016327911987900734, 0.022888602688908577, 0.060077644884586334, -0.02204807475209236, 0.008384522050619125, 0.01354517973959446, 0.012128133326768875, 0.00919675175100565, 0.008786987513303757, 0.00919675175100565], \"name\": \"predictions\"}, {\"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256], \"y\": [-0.003552236290177646, -0.012666909008795635, -0.02076749412872969, 0.02508600208473588, 0.020780129620841414, 0.004654803302791777, 0.020727462293734344, 0.01816358159240261, -0.010888220024617201, 0.024678120361828704, 0.0010718580379895926, -0.059421056913079084, -0.039021012703291724, -0.024073395399226705, 0.014394114070797936, 0.010046625989691638, -0.028507186052972422, 0.0012971554710761168, 0.0008693014152818535, -0.049314935004217464, -0.024496713763953792, 0.026509842793672966, 0.005519572448409615, -0.006706312063975428, -0.026541743220834135, -0.03431845910632925, 0.034283114050215335, 0.0018362883894273985, -0.0025080819265821397, 0.05103948649400092, -0.020509012139859006, 0.021348896621132596, -0.010855083756600603, 0.013437504616918172, 0.007059147341333727, 0.010339814022492622, 0.002761206823129747, -0.02029415582679661, 0.0180101306790732, 0.008844107566840176, -0.008646719666077995, -0.006385475402310714, 0.0051676288650086555, -0.02653206641560013, 0.005363028285598315, -0.004551669214718945, 0.02116534197070319, -0.01164738624918149, -0.001121968082998137, -0.01572202773059672, 0.0011057337669400091, 0.0134259673215813, 0.003282535186605706, 0.01989835389060879, 0.03681594791059961, 0.004869794108321557, 0.03552113023246983, -0.006423548633785803, -0.00821876224209861, -0.006658091902823404, 0.012797883097884988, -0.004570560103813737, -0.0007843077348783645, 0.00776973726436081, -0.003011843245432022, 0.0035307370974995145, 0.01842819778156901, 0.03155207922597869, 0.0033326119375605145, -0.019692116984326713, 0.009923745562807618, -0.004656006302834026, -0.008903623192677568, -0.015368619884505996, 0.04134030963497182, 0.07869562194433621, -0.020900204930283106, -0.0005175842552005427, 0.050929463035037426, 0.021404822615597396, -0.04125509845612285, 0.02951417869882267, -0.02491543952770403, -0.011596594160742768, -0.009179095640128754, 0.0026273825755209756, -0.007579153394410287, 0.006695193195417115, -0.013870184717053924, -0.016451862454175625, 0.02164196279692998, 0.005835399463695712, -0.006105757419273772, 0.015561175753995293, 0.010329028745721835, -0.0003294089773970832, 0.022349555785669217, -0.005868000138693041, -0.014717190097367272, 0.01813360773825501, -0.013016157913833926, 0.021186190557160423, 0.013604959418924256, 0.0003286023057005316, 0.0042746154578607864, 0.009878694826445322, 0.0030601986885776533, 0.014574677543021775, 0.00852012979424499, -0.003550371532919705, 0.007414677587578744, -0.005941932234082792, -0.016469099433571888, 0.020183913169818712, -0.006394147941726214, -0.00757741673474932, -0.0050754651609259405, 0.008154976590823093, 0.0046686224391701, 0.028641891547904308, 0.027048894071283414, 0.02517883095304807, 0.008153619080335073, 0.005539564105277339, 0.000920284577006214, 0.018654369142237837, 0.0514129434895092, 0.039099495130596296, -0.04868235889347661, 0.004361568957226947, -0.023924284289515096, 0.03962979477076756, -0.05719811148822895, 0.004709398319483249, 0.03391232759581042, -0.005190530861983511, 0.00888162704403106, 0.001089126990942102, -0.02807017411997892, -0.022121552330685912, -0.003483353871875927, -0.03245078230440157, 0.0272523761779202, -0.01615039011257169, -0.026060770512618348, -0.026357682586857223, -0.012251192910883724, 0.08687129278985495, -0.01849851719913609, 0.01659500497357369, -0.017419214503096025, -0.0005907300145593375, -0.012035162344166572, 0.012603606994637584, 0.013161798839348204, -0.009724585713193346, 0.008690322918270876, -0.01798347911028797, -0.003930601949734935, -0.01584445343334595, -0.0022202902364107935, -0.014413811447370417, 0.017765239511832842, 0.006612629018152294, 0.01344253167288123, -0.0025102552572535686, -0.016780113231626537, 0.004815007509873848, -0.005328609411218821, -0.008368825282802916, -0.0103452789767422, -0.0015831997905433326, 0.017942775068036543, 0.0021033386812434607, 0.00905991726331079, -0.0036163944661851133, 0.012886514523055226, -0.00924748794189778, 0.004561217305778964, -0.005240403666658899, -0.0013824364807910605, -0.010166140687778213, 0.0060073273396024085, 0.03571188990388929, 0.001482156754120112, 0.00018648632396267573, -0.004804873481925043, 0.0011345800242237303, 0.00018713707845563476, 0.0013089798977179434, 0.002755351897718139, -0.005749827570366239, 0.0035988879001749297, 0.00027461211211976533, 0.0029610154879780026, -0.0074080111927159464, -0.0008387780820218182, 0.009833353056404537, -0.0026274031207504933, 0.002233732464906879, 0.013892053952895278, -0.0022461242219335986, 0.008568589961420514, 0.009419992313639547, -0.0068187651664857185, 0.006861236577923258, 0.0009975592464730454, 0.006755032478160672, -0.008953103945650742, 0.00037199415866684404, 0.011074942267074839, 0.006390266670196265, 0.02043450276221037, 0.017444661444583787, -0.010511517848760477, 0.017225306281879682, -0.01309849494766313, -0.016085864273492678, 0.00376667608072756, -0.018684594916501318, 0.010403889878631833, -0.0012609690459575162, 0.0021179334827565732, 0.0033382476368024605, 0.003142589777704874, 0.006011120237823686, 0.0016904969604936149, 0.006339310113588237, 0.00041445749624102746, 0.004567852534890893, -0.013103852276032946, -0.010255869656194516, 0.00793931752599164, -0.004228509277415693, -0.00174575671525945, 0.0022176145101808764, -6.153404372932769e-05, -0.0010055924094016788, 0.014047837925851958, -0.002838491829178391, 0.0012681795209621427, 0.0027439026171340863, 0.009659966443797074, 0.009339388217148414, -0.024494709617237653, 0.006101844411858348, -0.003157769516003217, -0.007294809512189637, 0.003923631891638024, -0.010408346951558567, 0.002453359200121241, -0.002042335539923723, -0.009164718304578656, -0.0014006694376167417, -0.017966593856288515, -0.010274590607841194, -0.007719314005821598], \"name\": \"actual\"}], {}, {\"scrollZoom\": true, \"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"ee03aa61-46d4-43be-9472-c5056ceee0c9\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"ee03aa61-46d4-43be-9472-c5056ceee0c9\", [{\"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256], \"y\": [0.045086778700351715, 0.0583319216966629, -0.007984213531017303, -0.08746018260717392, -0.11182944476604462, 0.013724563643336296, 0.0460851825773716, 0.1292824000120163, -0.016640646383166313, -0.022218773141503334, -0.05492708459496498, -0.0686476081609726, -0.04582185670733452, 0.002434684894979, -0.07079704105854034, -0.023117927834391594, 0.033930856734514236, 0.020772624760866165, 0.008738646283745766, 0.009380806237459183, -0.00012146774679422379, 0.10657311975955963, 0.018091246485710144, 0.05051198974251747, -0.015306195244193077, 0.06934100389480591, 0.11616328358650208, 0.09180769324302673, 0.07902227342128754, 0.07042594999074936, 0.021266702562570572, -0.016931351274251938, -0.0009234822355210781, 0.024283835664391518, 0.0002593561075627804, -0.0021306215785443783, -0.02749180607497692, 0.020989352837204933, 0.020122436806559563, 0.06571320444345474, -0.019914593547582626, 0.009798762388527393, 0.008820061571896076, 0.008505311794579029, 0.017606783658266068, 0.010712004266679287, 0.0012511704117059708, 0.16838955879211426, 0.11694062501192093, 0.08431046456098557, 0.07280629873275757, 0.05673797056078911, 0.011181285604834557, -0.012214487418532372, -0.07363977283239365, -0.05027727410197258, -0.01785343699157238, 0.008009696379303932, 0.00919675175100565, 0.00919675175100565, 0.00900033488869667, 0.00919675175100565, 0.00919675175100565, 0.009107417427003384, 0.005815061274915934, 0.00919675175100565, 0.009153824299573898, 0.007934702560305595, 0.00919675175100565, 0.00919675175100565, 0.00919675175100565, 0.0020048734731972218, -0.018240973353385925, -0.03168525919318199, -0.0460522323846817, -0.07322421669960022, -0.01029282622039318, 0.0052447859197855, -9.295390918850899e-05, -0.011267520487308502, 0.00919675175100565, -0.018961818888783455, -0.018961818888783455, -0.018961818888783455, -0.018961818888783455, -0.0891423299908638, 0.00919675175100565, -0.021515026688575745, -0.024272290989756584, -0.04984211549162865, 0.04641090705990791, 0.013191483914852142, 0.02919689007103443, 0.02733277902007103, 0.019159790128469467, -0.05648744851350784, -0.09721854329109192, -0.014761419966816902, -0.05037733167409897, -0.09561466425657272, -0.12195771932601929, -0.022218773141503334, 0.03005482442677021, 0.01570991985499859, -0.04656394198536873, -0.04089634120464325, -0.028769752010703087, -0.05037733167409897, -0.05037733167409897, -0.05037733167409897, -0.049661338329315186, -0.05037733167409897, -0.021199146285653114, -0.06872569024562836, -0.022218773141503334, -0.0799148753285408, -0.0047289044596254826, -0.032484132796525955, -0.02150607481598854, -0.022058267146348953, -0.005553503055125475, 0.03211086243391037, -0.016555670648813248, -0.023746389895677567, -0.03141875937581062, -0.05037733167409897, -0.0504850409924984, -0.05037733167409897, -0.060873180627822876, -0.03493816405534744, -0.05037733167409897, -0.027647117152810097, 0.0493026077747345, -0.022218773141503334, -0.04485614597797394, -0.09050162136554718, -0.033144041895866394, -0.017350314185023308, -0.08890937268733978, -0.01792149245738983, 0.004621198400855064, 0.014483870938420296, -0.08385836333036423, -0.0425848588347435, 0.0028700740076601505, -0.022048674523830414, 0.009314199909567833, 0.005585612263530493, 0.00919675175100565, -0.008288029581308365, -0.023101763799786568, 0.009690255858004093, -0.009992608800530434, 0.0073599801398813725, 0.041213832795619965, -0.06890175491571426, -0.0616241917014122, -0.020165516063570976, -0.0485403910279274, -0.03632477670907974, 0.05061958730220795, -0.002550204750150442, 0.008815579116344452, 0.008216341026127338, 0.021433956921100616, -0.055460475385189056, -0.12879011034965515, -0.05928512662649155, -0.024296944960951805, -0.02251381240785122, -0.03410797566175461, -0.04629099369049072, -0.03294806927442551, -0.020668944343924522, -0.024016423150897026, -0.05671832710504532, 0.00023849261924624443, 0.014760259538888931, -0.07631704956293106, -0.06682775914669037, -0.05018901824951172, -0.047944746911525726, 0.005481370724737644, 0.05451349914073944, 0.014230391010642052, -0.002416305709630251, 0.0052975742146372795, 0.002470380626618862, -0.022335559129714966, 0.0023713866248726845, -0.029490338638424873, -0.002020613756030798, -0.04181506484746933, -0.0905674546957016, -0.11461661756038666, -0.09981344640254974, 0.00919675175100565, 0.00919675175100565, -0.05889182537794113, -0.05613374710083008, -0.0573781356215477, 0.00919675175100565, -0.002518783789128065, -0.00712713273242116, 0.00919675175100565, 0.008126111701130867, 0.008504753932356834, 0.008863432332873344, -0.020627638325095177, -0.012867739424109459, -0.022407090291380882, -0.018727179616689682, -0.04502754285931587, -0.03494659811258316, 0.06019013002514839, 0.03206430375576019, 0.03175055980682373, -0.03082754649221897, -0.02264486253261566, -0.07939687371253967, -0.0514070950448513, 0.0017383904196321964, -0.03174985200166702, -0.04041034355759621, -0.0491541363298893, -0.007376226130872965, -0.012452445924282074, 0.015352251008152962, -7.248762995004654e-05, -0.04856143891811371, -0.031122298911213875, 0.010568695142865181, 0.018730787560343742, 0.0507691465318203, 0.027392003685235977, 0.019535765051841736, -0.05796778202056885, -0.05796778202056885, -0.036209482699632645, 0.014706199988722801, 0.05495947599411011, 0.015464892610907555, -0.07718844711780548, -0.01683049276471138, -0.017957357689738274, -0.0575641468167305, 0.009051918983459473, 0.016327911987900734, 0.022888602688908577, 0.060077644884586334, -0.02204807475209236, 0.008384522050619125, 0.01354517973959446, 0.012128133326768875, 0.00919675175100565, 0.008786987513303757, 0.00919675175100565], \"name\": \"predictions\"}, {\"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256], \"y\": [-0.003552236290177646, -0.012666909008795635, -0.02076749412872969, 0.02508600208473588, 0.020780129620841414, 0.004654803302791777, 0.020727462293734344, 0.01816358159240261, -0.010888220024617201, 0.024678120361828704, 0.0010718580379895926, -0.059421056913079084, -0.039021012703291724, -0.024073395399226705, 0.014394114070797936, 0.010046625989691638, -0.028507186052972422, 0.0012971554710761168, 0.0008693014152818535, -0.049314935004217464, -0.024496713763953792, 0.026509842793672966, 0.005519572448409615, -0.006706312063975428, -0.026541743220834135, -0.03431845910632925, 0.034283114050215335, 0.0018362883894273985, -0.0025080819265821397, 0.05103948649400092, -0.020509012139859006, 0.021348896621132596, -0.010855083756600603, 0.013437504616918172, 0.007059147341333727, 0.010339814022492622, 0.002761206823129747, -0.02029415582679661, 0.0180101306790732, 0.008844107566840176, -0.008646719666077995, -0.006385475402310714, 0.0051676288650086555, -0.02653206641560013, 0.005363028285598315, -0.004551669214718945, 0.02116534197070319, -0.01164738624918149, -0.001121968082998137, -0.01572202773059672, 0.0011057337669400091, 0.0134259673215813, 0.003282535186605706, 0.01989835389060879, 0.03681594791059961, 0.004869794108321557, 0.03552113023246983, -0.006423548633785803, -0.00821876224209861, -0.006658091902823404, 0.012797883097884988, -0.004570560103813737, -0.0007843077348783645, 0.00776973726436081, -0.003011843245432022, 0.0035307370974995145, 0.01842819778156901, 0.03155207922597869, 0.0033326119375605145, -0.019692116984326713, 0.009923745562807618, -0.004656006302834026, -0.008903623192677568, -0.015368619884505996, 0.04134030963497182, 0.07869562194433621, -0.020900204930283106, -0.0005175842552005427, 0.050929463035037426, 0.021404822615597396, -0.04125509845612285, 0.02951417869882267, -0.02491543952770403, -0.011596594160742768, -0.009179095640128754, 0.0026273825755209756, -0.007579153394410287, 0.006695193195417115, -0.013870184717053924, -0.016451862454175625, 0.02164196279692998, 0.005835399463695712, -0.006105757419273772, 0.015561175753995293, 0.010329028745721835, -0.0003294089773970832, 0.022349555785669217, -0.005868000138693041, -0.014717190097367272, 0.01813360773825501, -0.013016157913833926, 0.021186190557160423, 0.013604959418924256, 0.0003286023057005316, 0.0042746154578607864, 0.009878694826445322, 0.0030601986885776533, 0.014574677543021775, 0.00852012979424499, -0.003550371532919705, 0.007414677587578744, -0.005941932234082792, -0.016469099433571888, 0.020183913169818712, -0.006394147941726214, -0.00757741673474932, -0.0050754651609259405, 0.008154976590823093, 0.0046686224391701, 0.028641891547904308, 0.027048894071283414, 0.02517883095304807, 0.008153619080335073, 0.005539564105277339, 0.000920284577006214, 0.018654369142237837, 0.0514129434895092, 0.039099495130596296, -0.04868235889347661, 0.004361568957226947, -0.023924284289515096, 0.03962979477076756, -0.05719811148822895, 0.004709398319483249, 0.03391232759581042, -0.005190530861983511, 0.00888162704403106, 0.001089126990942102, -0.02807017411997892, -0.022121552330685912, -0.003483353871875927, -0.03245078230440157, 0.0272523761779202, -0.01615039011257169, -0.026060770512618348, -0.026357682586857223, -0.012251192910883724, 0.08687129278985495, -0.01849851719913609, 0.01659500497357369, -0.017419214503096025, -0.0005907300145593375, -0.012035162344166572, 0.012603606994637584, 0.013161798839348204, -0.009724585713193346, 0.008690322918270876, -0.01798347911028797, -0.003930601949734935, -0.01584445343334595, -0.0022202902364107935, -0.014413811447370417, 0.017765239511832842, 0.006612629018152294, 0.01344253167288123, -0.0025102552572535686, -0.016780113231626537, 0.004815007509873848, -0.005328609411218821, -0.008368825282802916, -0.0103452789767422, -0.0015831997905433326, 0.017942775068036543, 0.0021033386812434607, 0.00905991726331079, -0.0036163944661851133, 0.012886514523055226, -0.00924748794189778, 0.004561217305778964, -0.005240403666658899, -0.0013824364807910605, -0.010166140687778213, 0.0060073273396024085, 0.03571188990388929, 0.001482156754120112, 0.00018648632396267573, -0.004804873481925043, 0.0011345800242237303, 0.00018713707845563476, 0.0013089798977179434, 0.002755351897718139, -0.005749827570366239, 0.0035988879001749297, 0.00027461211211976533, 0.0029610154879780026, -0.0074080111927159464, -0.0008387780820218182, 0.009833353056404537, -0.0026274031207504933, 0.002233732464906879, 0.013892053952895278, -0.0022461242219335986, 0.008568589961420514, 0.009419992313639547, -0.0068187651664857185, 0.006861236577923258, 0.0009975592464730454, 0.006755032478160672, -0.008953103945650742, 0.00037199415866684404, 0.011074942267074839, 0.006390266670196265, 0.02043450276221037, 0.017444661444583787, -0.010511517848760477, 0.017225306281879682, -0.01309849494766313, -0.016085864273492678, 0.00376667608072756, -0.018684594916501318, 0.010403889878631833, -0.0012609690459575162, 0.0021179334827565732, 0.0033382476368024605, 0.003142589777704874, 0.006011120237823686, 0.0016904969604936149, 0.006339310113588237, 0.00041445749624102746, 0.004567852534890893, -0.013103852276032946, -0.010255869656194516, 0.00793931752599164, -0.004228509277415693, -0.00174575671525945, 0.0022176145101808764, -6.153404372932769e-05, -0.0010055924094016788, 0.014047837925851958, -0.002838491829178391, 0.0012681795209621427, 0.0027439026171340863, 0.009659966443797074, 0.009339388217148414, -0.024494709617237653, 0.006101844411858348, -0.003157769516003217, -0.007294809512189637, 0.003923631891638024, -0.010408346951558567, 0.002453359200121241, -0.002042335539923723, -0.009164718304578656, -0.0014006694376167417, -0.017966593856288515, -0.010274590607841194, -0.007719314005821598], \"name\": \"actual\"}], {}, {\"scrollZoom\": true, \"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot as it is\n",
    "predLine = Scatter(\n",
    "            x=np.arange(pred.shape[0]),\n",
    "            y=pred.flatten(),\n",
    "            name='predictions'\n",
    "            )\n",
    "actualLine = Scatter(\n",
    "            x=np.arange(ytest.shape[0]),\n",
    "            y=ytest.flatten(),\n",
    "            name='actual'\n",
    "            )\n",
    "iplot([predLine, actualLine], config={ \"scrollZoom\": True })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for errors\n",
    "# Save the model for later\n",
    "# Try predicting a few minutes ahead one-by-one\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
